{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc11486e-be42-412c-b5fc-b38c04110529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/04/07 18:30:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, monotonically_increasing_id\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "app_name = \"MiscTransformations\"\n",
    "spark: SparkSession = (\n",
    "    SparkSession.builder.master(\"local[3]\")\n",
    "    .appName(app_name)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1713d3d-61a1-4742-999d-57a578d3919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdea48c-9aca-45f5-9a69-383218f7cb07",
   "metadata": {},
   "source": [
    "# Quick method to create dataframe\n",
    "\n",
    "- mainly for testing, exploring some techniques\n",
    "- skipped parallizing the data, creating RDD, creating schema definition etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe66d9d-41d2-4a85-8ff4-a133062dd837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+----+\n",
      "|   _1| _2| _3|  _4|\n",
      "+-----+---+---+----+\n",
      "| Ravi| 28|  1|2002|\n",
      "|Abdul| 23|  5|  81|\n",
      "| John| 12| 12|   6|\n",
      "| Rosy|  7|  8|  63|\n",
      "|Abdul| 23|  5|  81|\n",
      "+-----+---+---+----+\n",
      "\n",
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      " |-- _3: long (nullable = true)\n",
      " |-- _4: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataList = [\n",
    "    (\"Ravi\", 28, 1, 2002),\n",
    "    (\"Abdul\", 23, 5, 81),\n",
    "    (\"John\", 12, 12, 6),\n",
    "    (\"Rosy\", 7, 8, 63),\n",
    "    (\"Abdul\", 23, 5, 81),\n",
    "]\n",
    "\n",
    "rawDF = spark.createDataFrame(dataList)\n",
    "rawDF.show()\n",
    "rawDF.printSchema()  # can use namedtuple to create schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8cfcd5-f9e5-45f7-8614-e4d9ea3f040d",
   "metadata": {},
   "source": [
    "# Quick way to attach column names\n",
    "\n",
    "- `toDF()`: _returns a new DataFrame that with new specified column names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a4539a-ee26-4bf4-b3c0-69ef2b746d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+\n",
      "| name|day|month|year|\n",
      "+-----+---+-----+----+\n",
      "| Ravi| 28|    1|2002|\n",
      "|Abdul| 23|    5|  81|\n",
      "| John| 12|   12|   6|\n",
      "| Rosy|  7|    8|  63|\n",
      "|Abdul| 23|    5|  81|\n",
      "+-----+---+-----+----+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: long (nullable = true)\n",
      " |-- month: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawDFCol = spark.createDataFrame(dataList).toDF(\"name\", \"day\", \"month\", \"year\")\n",
    "rawDFCol.show()\n",
    "rawDFCol.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3407f8-c56f-451c-a803-4a95dc387fa5",
   "metadata": {},
   "source": [
    "# Some problems\n",
    "\n",
    "- changed to string to show the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa74da7-ca5b-4369-b189-c3164ff841d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+\n",
      "| name|day|month|year|\n",
      "+-----+---+-----+----+\n",
      "| Ravi| 28|    1|2002|\n",
      "|Abdul| 23|    5|  81|\n",
      "| John| 12|   12|   6|\n",
      "| Rosy|  7|    8|  63|\n",
      "|Abdul| 23|    5|  81|\n",
      "+-----+---+-----+----+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataList = [\n",
    "    (\"Ravi\", \"28\", \"1\", \"2002\"),\n",
    "    (\"Abdul\", \"23\", \"5\", \"81\"),\n",
    "    (\"John\", \"12\", \"12\", \"6\"),\n",
    "    (\"Rosy\", \"7\", \"8\", \"63\"),\n",
    "    (\"Abdul\", \"23\", \"5\", \"81\"),\n",
    "]\n",
    "\n",
    "rawDF = spark.createDataFrame(dataList).toDF(\"name\", \"day\", \"month\", \"year\")\n",
    "rawDF.show()\n",
    "rawDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92947adb-d553-4be9-afdc-541fee5e3efe",
   "metadata": {},
   "source": [
    "# How to add monotonically increasing id\n",
    "\n",
    "- `from pyspark.sql.functions import monotonically_increasing_id`\n",
    "- generates monotonically increasing 64-bit integers that are guaranteed to be unique and increasing, but not consecutive, within a partition.\n",
    "- The ID starts at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0689462-9d33-46a3-bb71-c463e123d459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+\n",
      "| name|day|month|year|\n",
      "+-----+---+-----+----+\n",
      "| Ravi| 28|    1|2002|\n",
      "|Abdul| 23|    5|  81|\n",
      "|Abdul| 23|    5|  81|\n",
      "| John| 12|   12|   6|\n",
      "| Rosy|  7|    8|  63|\n",
      "+-----+---+-----+----+\n",
      "\n",
      "+-----+---+-----+----+-----------+\n",
      "| name|day|month|year|         id|\n",
      "+-----+---+-----+----+-----------+\n",
      "| Ravi| 28|    1|2002|          0|\n",
      "|Abdul| 23|    5|  81|          1|\n",
      "|Abdul| 23|    5|  81| 8589934592|\n",
      "| John| 12|   12|   6|17179869184|\n",
      "| Rosy|  7|    8|  63|17179869185|\n",
      "+-----+---+-----+----+-----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawDF = (\n",
    "    spark.createDataFrame(dataList)\n",
    "    .toDF(\n",
    "        \"name\",\n",
    "        \"day\",\n",
    "        \"month\",\n",
    "        \"year\",\n",
    "    )\n",
    "    .repartition(3)  # in local, to sense real behvaior, remove in production, for repartition(1) id is consecutive\n",
    ")\n",
    "\n",
    "rawDF.show()\n",
    "\n",
    "df1 = rawDF.withColumn(\"id\", monotonically_increasing_id())\n",
    "# withColumn(colName: str, col: Column) -> \"DataFrame\"\n",
    "# Returns a new `DataFrame` by adding a column or replacing the\n",
    "# existing column that has the same name.\n",
    "df1.show()\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742192fe-0220-4949-a264-05f7109817ac",
   "metadata": {},
   "source": [
    "# How to use CASE, WHEN, THEN\n",
    "\n",
    "- avoid lengthy if-else statements\n",
    "- _lte's fix year digit problem using it_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c83daddd-1b16-4a71-92b0-a910be9323c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+------+-----------+\n",
      "| name|day|month|  year|         id|\n",
      "+-----+---+-----+------+-----------+\n",
      "| Ravi| 28|    1|  2002|          0|\n",
      "|Abdul| 23|    5|1981.0|          1|\n",
      "|Abdul| 23|    5|1981.0| 8589934592|\n",
      "| John| 12|   12|2006.0|17179869184|\n",
      "| Rosy|  7|    8|1963.0|17179869185|\n",
      "+-----+---+-----+------+-----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataList = [\n",
    "    (\"Ravi\", \"28\", \"1\", \"2002\"),\n",
    "    (\"Abdul\", \"23\", \"5\", \"81\"),  # 1981\n",
    "    (\"John\", \"12\", \"12\", \"6\"),  # 2006\n",
    "    (\"Rosy\", \"7\", \"8\", \"63\"),  # 1963\n",
    "    (\"Abdul\", \"23\", \"5\", \"81\"),  # 1981\n",
    "]\n",
    "\n",
    "df2 = df1.withColumn(\n",
    "    \"year\",\n",
    "    expr(\"\"\"\n",
    "    CASE\n",
    "        WHEN year < 25 THEN year + 2000\n",
    "        WHEN year < 100 THEN year + 1900\n",
    "        ELSE\n",
    "            year\n",
    "    END\n",
    "    \"\"\"),\n",
    ")\n",
    "\n",
    "df2.show()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a457ce5-967e-413c-9e47-7c02872d4f38",
   "metadata": {},
   "source": [
    "- year is string, but operations were done considering number with decimal. So, year became decimal.\n",
    "- **_REASON:_** incorrect datatype and automatic type promotion. year field in the dataframe is a string. But we performed an arithmetic operation on it, so spark SQL Engine automatically promoted it to decimal. After that again, it's demoted to string because the dataframe schema is for a string field.\n",
    "- **_FIX:_** to cast fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f468445-514c-4caa-8786-861c982c6e41",
   "metadata": {},
   "source": [
    "# How to cast fields?\n",
    "\n",
    "Two common approaches\n",
    "- **_Inline cast_**\n",
    "- **_Change the Schema_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca03f00e-6a9d-4bf5-8032-323c838ae587",
   "metadata": {},
   "source": [
    "# Inline Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de1136a1-350e-46c8-84c9-7bdf1c033688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+-----------+\n",
      "| name|day|month|year|         id|\n",
      "+-----+---+-----+----+-----------+\n",
      "| Ravi| 28|    1|2002|          0|\n",
      "|Abdul| 23|    5|1981|          1|\n",
      "|Abdul| 23|    5|1981| 8589934592|\n",
      "| John| 12|   12|2006|17179869184|\n",
      "| Rosy|  7|    8|1963|17179869185|\n",
      "+-----+---+-----+----+-----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df1.withColumn(\n",
    "    \"year\",\n",
    "    expr(\n",
    "        \"\"\"\n",
    "        CASE\n",
    "            WHEN year < 25 THEN CAST(year AS INT) + 2000\n",
    "            WHEN year < 100 THEN CAST(year AS INT) + 1900\n",
    "            ELSE\n",
    "                YEAR\n",
    "        END\n",
    "        \"\"\"\n",
    "    ),\n",
    ")\n",
    "df3.show()\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd77f8-5459-408e-9be1-c3450896c008",
   "metadata": {},
   "source": [
    "# Change the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "461646c8-abd6-480c-be48-09fe0609b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+-----------+\n",
      "| name|day|month|year|         id|\n",
      "+-----+---+-----+----+-----------+\n",
      "| Ravi| 28|    1|2002|          0|\n",
      "|Abdul| 23|    5|1981|          1|\n",
      "|Abdul| 23|    5|1981| 8589934592|\n",
      "| John| 12|   12|2006|17179869184|\n",
      "| Rosy|  7|    8|1963|17179869185|\n",
      "+-----+---+-----+----+-----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = df1.withColumn(\n",
    "    \"year\",\n",
    "    expr(\n",
    "        \"\"\"\n",
    "        CASE\n",
    "            WHEN year < 25 THEN year + 2000\n",
    "            WHEN year < 100 THEN year + 1900\n",
    "            ELSE\n",
    "                YEAR\n",
    "        END\n",
    "        \"\"\"\n",
    "    ).cast(IntegerType()),\n",
    ")\n",
    "\n",
    "# df4 = df4.withColumn(\"year\", df4[\"year\"].cast(\"int\"))  # this works too\n",
    "df4.show()\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7e23e-bc5c-4864-9c0b-6c1e86b44844",
   "metadata": {},
   "source": [
    "# The right way\n",
    "\n",
    "Should have fixed the data types in the beginning and avoided casting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5ada951-990d-4553-b8ad-71630ba88260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+-----------+\n",
      "| name|day|month|year|         id|\n",
      "+-----+---+-----+----+-----------+\n",
      "| Ravi| 28|    1|2002|          0|\n",
      "|Abdul| 23|    5|  81|          1|\n",
      "|Abdul| 23|    5|  81| 8589934592|\n",
      "| John| 12|   12|   6|17179869184|\n",
      "| Rosy|  7|    8|  63|17179869185|\n",
      "+-----+---+-----+----+-----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aea06eee-5ee5-4c0f-bedb-2155c6af6869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+-----------+\n",
      "| name|day|month|year|         id|\n",
      "+-----+---+-----+----+-----------+\n",
      "| Ravi| 28|    1|2002|          0|\n",
      "|Abdul| 23|    5|1981|          1|\n",
      "|Abdul| 23|    5|1981| 8589934592|\n",
      "| John| 12|   12|2006|17179869184|\n",
      "| Rosy|  7|    8|1963|17179869185|\n",
      "+-----+---+-----+----+-----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df5 = (\n",
    "    df1.withColumn(\"day\", col(\"day\").cast(IntegerType()))\n",
    "    .withColumn(\"month\", col(\"month\").cast(IntegerType()))\n",
    "    .withColumn(\"year\", col(\"year\").cast(IntegerType()))\n",
    ")\n",
    "\n",
    "df6 = df5.withColumn(\n",
    "    \"year\",\n",
    "    expr(\"\"\"\n",
    "        CASE\n",
    "            WHEN year < 25 THEN year + 2000\n",
    "            WHEN year < 100 THEN year + 1900\n",
    "            ELSE\n",
    "                year\n",
    "        END\n",
    "        \"\"\"),\n",
    ")\n",
    "df6.show()\n",
    "df6.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f79f02a-1e7e-492e-a501-93ce79cb3eb4",
   "metadata": {},
   "source": [
    "> Remember, incorrect types can give some unexpected results. Explicit casting is always a good option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3bc67-1570-4f50-9792-66e472255747",
   "metadata": {},
   "source": [
    "# Alternative Method to CASE expression\n",
    "\n",
    "- SQL like expression is more convinient and can be preferred.\n",
    "- we learnt to build our expressions using columns, functions.\n",
    "\n",
    "Let's see column object expression for the CASE expression using same `withColumn()` and work with the same `year` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a75baa87-fa2b-4c81-98c5-61f8ef613331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+-----------+\n",
      "| name|day|month|year|         id|\n",
      "+-----+---+-----+----+-----------+\n",
      "| Ravi| 28|    1|2002|          0|\n",
      "|Abdul| 23|    5|  81|          1|\n",
      "|Abdul| 23|    5|  81| 8589934592|\n",
      "| John| 12|   12|   6|17179869184|\n",
      "| Rosy|  7|    8|  63|17179869185|\n",
      "+-----+---+-----+----+-----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show()\n",
    "df5.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e50a48a2-306f-4910-843d-783ffc406d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+-----------+\n",
      "| name|day|month|year|         id|\n",
      "+-----+---+-----+----+-----------+\n",
      "| Ravi| 28|    1|2002|          0|\n",
      "|Abdul| 23|    5|1981|          1|\n",
      "|Abdul| 23|    5|1981| 8589934592|\n",
      "| John| 12|   12|2006|17179869184|\n",
      "| Rosy|  7|    8|1963|17179869185|\n",
      "+-----+---+-----+----+-----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "\n",
    "df7 = df5.withColumn(\n",
    "    \"year\",\n",
    "    when(col(\"year\") < 25, col(\"year\") + 2000)\n",
    "    .when(col(\"year\") < 100, col(\"year\") + 1900)\n",
    "    .otherwise(col(\"year\")),\n",
    ")\n",
    "\n",
    "df7.show()\n",
    "df7.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c291fb03-e187-4100-a8f4-60519fb039de",
   "metadata": {},
   "source": [
    "# How to Add/Remove columns and duplicates?\n",
    "\n",
    "- we already added column previously using `monotonically_increasing_id()`\n",
    "- let's add one more column `dob` combining `date`, `month`, `year` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "947db83b-86fd-41ae-9c96-f49fdcfcfe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+-----------+\n",
      "| name|day|month|year|         id|\n",
      "+-----+---+-----+----+-----------+\n",
      "| Ravi| 28|    1|2002|          0|\n",
      "|Abdul| 23|    5|1981|          1|\n",
      "|Abdul| 23|    5|1981| 8589934592|\n",
      "| John| 12|   12|2006|17179869184|\n",
      "| Rosy|  7|    8|1963|17179869185|\n",
      "+-----+---+-----+----+-----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7.show()\n",
    "df7.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff25dd84-1e17-4e8f-a62d-65ce04e7f16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+-----------+----------+\n",
      "| name|day|month|year|         id|       dob|\n",
      "+-----+---+-----+----+-----------+----------+\n",
      "| Ravi| 28|    1|2002|          0|2002-01-28|\n",
      "|Abdul| 23|    5|1981|          1|1981-05-23|\n",
      "|Abdul| 23|    5|1981| 8589934592|1981-05-23|\n",
      "| John| 12|   12|2006|17179869184|2006-12-12|\n",
      "| Rosy|  7|    8|1963|17179869185|1963-08-07|\n",
      "+-----+---+-----+----+-----------+----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      " |-- dob: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df8 = df7.withColumn(\n",
    "    \"dob\",\n",
    "    expr(\"to_date(CONCAT(day, '/', month, '/', year), 'd/M/y')\"),\n",
    ")\n",
    "df8.show()\n",
    "df8.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a9852-ada7-4c17-a356-cca6f630863f",
   "metadata": {},
   "source": [
    "**OR**\n",
    "\n",
    "- `to_date` from `pyspark.sql.functions`: _outside `expr`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf92f3b4-8577-49c2-982f-95b15449ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+-----------+----------+\n",
      "| name|day|month|year|         id|       dob|\n",
      "+-----+---+-----+----+-----------+----------+\n",
      "| Ravi| 28|    1|2002|          0|2002-01-28|\n",
      "|Abdul| 23|    5|1981|          1|1981-05-23|\n",
      "|Abdul| 23|    5|1981| 8589934592|1981-05-23|\n",
      "| John| 12|   12|2006|17179869184|2006-12-12|\n",
      "| Rosy|  7|    8|1963|17179869185|1963-08-07|\n",
      "+-----+---+-----+----+-----------+----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      " |-- dob: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "\n",
    "df9 = df7.withColumn(\n",
    "    \"dob\",\n",
    "    to_date(expr(\"CONCAT(day, '/', month, '/', year)\"), \"d/M/y\"),\n",
    ")\n",
    "df9.show()\n",
    "df9.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d788e21-ac43-4b6a-a83e-b3e7a1d7cd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+----------+\n",
      "| name|         id|       dob|\n",
      "+-----+-----------+----------+\n",
      "| John|17179869184|2006-12-12|\n",
      "| Ravi|          0|2002-01-28|\n",
      "|Abdul|          1|1981-05-23|\n",
      "| Rosy|17179869185|1963-08-07|\n",
      "+-----+-----------+----------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      " |-- dob: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df10 = (\n",
    "    df7.withColumn(\n",
    "        \"dob\",\n",
    "        to_date(expr(\"CONCAT(day, '/', month, '/', year)\"), \"d/M/y\"),\n",
    "    )\n",
    "    .drop(\"day\", \"month\", \"year\")\n",
    "    .dropDuplicates([\"name\", \"dob\"])\n",
    "    # .sort(expr(\"dob DESC\"))  # will give ascending order\n",
    "    .sort(\"dob\", ascending=False)\n",
    ")\n",
    "\n",
    "df10.show()\n",
    "df10.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
